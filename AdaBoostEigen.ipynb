{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "yUrCBldeUPi7"
      },
      "outputs": [],
      "source": [
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# !kaggle datasets download -d kaustubhchaudhari/pubfig-dataset-256x256-jpg\n",
        "# !unzip pubfig-dataset-256x256-jpg.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "2D3Dx0UfUS-p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Set the path to your original dataset folder\n",
        "original_dataset_path = '/content/CelebDataProcessed'\n",
        "\n",
        "# Set the path to the folder where you want to create the train and test folders\n",
        "base_dir = '/content/Facesfolder'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Set the percentage of images to use for the test set\n",
        "test_split_percentage = 20\n",
        "\n",
        "# Create the train and test folders\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Iterate through each actor folder in the original dataset folder\n",
        "for actor_name in os.listdir(original_dataset_path):\n",
        "    actor_dir = os.path.join(original_dataset_path, actor_name)\n",
        "    if not os.path.isdir(actor_dir):\n",
        "        continue\n",
        "\n",
        "    train_actor_dir = os.path.join(train_dir, actor_name)\n",
        "    test_actor_dir = os.path.join(test_dir, actor_name)\n",
        "    os.makedirs(train_actor_dir, exist_ok=True)\n",
        "    os.makedirs(test_actor_dir, exist_ok=True)\n",
        "\n",
        "    actor_images = os.listdir(actor_dir)\n",
        "    random.shuffle(actor_images)\n",
        "    test_split_index = int(len(actor_images) * (test_split_percentage / 100))\n",
        "    train_images = actor_images[test_split_index:]\n",
        "    test_images = actor_images[:test_split_index]\n",
        "\n",
        "    for image_name in train_images:\n",
        "        image_path = os.path.join(actor_dir, image_name)\n",
        "        target_path = os.path.join(train_actor_dir, image_name)\n",
        "        shutil.copy(image_path, target_path)\n",
        "\n",
        "    for image_name in test_images:\n",
        "        image_path = os.path.join(actor_dir, image_name)\n",
        "        target_path = os.path.join(test_actor_dir, image_name)\n",
        "        shutil.copy(image_path, target_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6XOdoBnaTRQR"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "import os\n",
        "\n",
        "def load_dataset(data_dir):\n",
        "  test_images = []\n",
        "  test_labels = []\n",
        "  for label, folder_name in enumerate(os.listdir(data_dir)):\n",
        "      folder_path = os.path.join(data_dir, folder_name)\n",
        "      for filename in os.listdir(folder_path):\n",
        "          image_path = os.path.join(folder_path, filename)\n",
        "          image = cv2.imread(image_path, 0)\n",
        "          # image = cv2.resize(image, (100, 100))\n",
        "          test_images.append(image)\n",
        "          test_labels.append(label)\n",
        "  test_images = np.array(test_images)\n",
        "  test_labels = np.array(test_labels)\n",
        "\n",
        "  return test_images,test_labels\n",
        "\n",
        "## Extract eigen faces:\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "X,y=load_dataset(\"/content/Facesfolder/train\")\n",
        "\n",
        "n_samples = X.shape[0]\n",
        "X_flat = X.reshape(n_samples, -1)\n",
        "\n",
        "n_components = 50 # number of eigenfaces to extract\n",
        "pca = PCA(n_components=n_components, whiten=True)\n",
        "X_pca = pca.fit_transform(X_flat)\n",
        "\n",
        "adaboost = AdaBoostClassifier(base_estimator=SVC(kernel='linear', C=1000, gamma='auto'), algorithm='SAMME')\n",
        "\n",
        "\n",
        "adaboost.fit(X_pca, y)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygLMMhs7xLCX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRp3dH88wyyu"
      },
      "outputs": [],
      "source": [
        "Xtest,ytest=load_dataset(\"/content/Facesfolder/test\")\n",
        "\n",
        "correct = 0\n",
        "total = len(ytest)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(total):\n",
        "    test_image = Xtest[i]\n",
        "    test_label = ytest[i]\n",
        "    test_image_pca = pca.transform(test_image.reshape(1, -1))\n",
        "    predicted_label = adaboost.predict(test_image_pca)[0]\n",
        "    if predicted_label == test_label:\n",
        "        correct += 1\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-Gz6l7zUqJM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "folder_path = '/content/Facesfolder/train'\n",
        "subfolders = [f.path for f in os.scandir(folder_path) if f.is_dir()]\n",
        "\n",
        "sum=0\n",
        "\n",
        "for subfolder_path in subfolders:\n",
        "    subfolder_name = os.path.basename(subfolder_path)\n",
        "    sum+= len(os.listdir(subfolder_path))\n",
        "\n",
        "print(sum)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/Cristiano Ronaldo.zip\" -d ./CR"
      ],
      "metadata": {
        "id": "y-xtN8MQg4Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAG_CvX344Od"
      },
      "outputs": [],
      "source": [
        "def folder_name_labels(data_dir):\n",
        "  test_images = []\n",
        "  test_labels = []\n",
        "\n",
        "  folder2label={}\n",
        "  for label, folder_name in enumerate(os.listdir(data_dir)):\n",
        "      folder_path = os.path.join(data_dir, folder_name)\n",
        "      # print(folder_name)\n",
        "\n",
        "      folder2label[folder_name]=label\n",
        "      \n",
        "\n",
        "  return folder2label    \n",
        "\n",
        "folder2label=folder_name_labels(\"/content/Facesfolder/test\")  \n",
        "\n",
        "\n",
        "print(folder2label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_dataset2(data_dir,folder2label):\n",
        "  test_images = []\n",
        "  test_labels = []\n",
        "  for label, folder_name in enumerate(os.listdir(data_dir)):\n",
        "      folder_path = os.path.join(data_dir, folder_name)\n",
        "      for filename in os.listdir(folder_path):\n",
        "          image_path = os.path.join(folder_path, filename)\n",
        "          image = cv2.imread(image_path, 0)\n",
        "          # image = cv2.resize(image, (100, 100))\n",
        "          test_images.append(image)\n",
        "          test_labels.append(folder2label[folder_name])\n",
        "  test_images = np.array(test_images)\n",
        "  test_labels = np.array(test_labels)\n",
        "\n",
        "  return test_images,test_labels\n",
        "\n"
      ],
      "metadata": {
        "id": "i8oMcyEeh2pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQaO4gjI46Yw"
      },
      "outputs": [],
      "source": [
        "Xtest,ytest=load_dataset2(\"/content/CR\",folder2label)\n",
        "\n",
        "correct = 0\n",
        "total = len(ytest)\n",
        "\n",
        "\n",
        "for i in range(total):\n",
        "    test_image = Xtest[i]\n",
        "    test_label = ytest[i]\n",
        "    test_image_pca = pca.transform(test_image.reshape(1, -1))\n",
        "    predicted_label = adaboost.predict(test_image_pca)[0]\n",
        "\n",
        "    print(predicted_label,test_label)\n",
        "    if predicted_label == test_label:\n",
        "        correct += 1\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RzzTmFLTf5WY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}